syntax = "proto3";

package management;

import "google/protobuf/empty.proto";

enum MemoryType {
  RAM = 0;  // memory for CPU
  VRAM = 1; // memory for GPU
}

enum ComputeType {
  CPU = 0;
  GPU = 1;
}

// route for management between controller and agent
// agent is client and controller is server (servicer)
service ManagementRoute {
  // agent uses register rpc to register itself in the controller
  rpc register(RegReq) returns (RegRes) {}
  // agent sends heart beat to the controller to signal its liveness
  rpc heartbeat(AgentID) returns (google.protobuf.Empty) {}
  // agent calls update rpc to provide status of workers
  rpc update(Status) returns (google.protobuf.Empty) {}
  // agent calls fetch rpc to obtain manifest for inference service
  rpc fetch(AgentID) returns (stream Manifest) {}
}

message AgentID {
  string id = 1;
}

message RegReq {
  string id = 1; // a unique string for an agent:
                 // ip address, host name or random string
}

message RegRes {
  bool status = 1;
  string reason = 2; // reason string in case of failure
}

// status contains details about resources and workers managed by an agent
message Status {
  string id = 1; // agent's id
  repeated ComputeStatus compute_statuses = 2;
  repeated MemoryStatus memory_statuses = 3;
  repeated WorkerStatus worker_statuses = 4;
}

message ComputeID {
  ComputeType type = 1; // CPU or GPU
  int32 id = 2; // resource id of the given type
                // 0: any in case of CPU;
                // 1...n: specific device index for a given type
                // CPU type has a specific id other than 0, it means cpu pinning
}

message MemoryID {
  MemoryType type = 1; // RAM or VRAM
  int32 id = 2; // resource id of the given type
                // 0: default value for RAM
                // 1...n: specific device index for a given type
                // since GPU is coupled with VRAM, GPU id and VRAM id should be matched
}

// computestatus contains status information about compute
message ComputeStatus {
  ComputeID cid = 1; // Compute identifier
  string sub_type = 2; // in case of GPU, GPU sub type is specified
  bool used = 3; // specify whether the resource is used or not
}

// memorystatus contains status information about memory
message MemoryStatus {
  MemoryID mid = 1; // Memory identifier
  int32 used = 2; // this would be an average value
  int32 total = 3;
}

// workerstatus contains information about worker's status
message WorkerStatus {
  int32 deploy_id = 1; // deployment is a unit that encapsulates deployed model's stages
                       // deploy id is an identifier for one deployment
  int32 worker_id = 2; // worker id within deployment; each id is unique within one deployment
  bool healthy = 3;    // true or false
  ComputeID cid = 4;   // compute id specifies computation device that worker is running
  MemoryID mid = 5;    // memory id specifies memory device; in case of GPU, it's the same sas compute id
  Statistics statistics = 6;
}

// statistics contains 
message Statistics {
  int32 throughput = 1; // requests (e.g., prompts) per second; can be an average value
  int32 latency_ms = 2; // delay in millisecond; can be an average value
}

// manifest contains details about configuring inference service
// TODO: for now, we keep this as byte stream; revisit this
//       once manifest's structure is confirmed
message Manifest {
  bytes payload = 1;
}

---
name: llama3 linear example
model: meta-llama/Meta-Llama-3.1-8B
nfaults: 1
# the following entries are for local development only
# after development is done, they need to be revised accordingly
# to automate building flow_graph, etc.
micro_batch_size: 2
fwd_policy: rr
job_id: "job5"
# maximum number of requests in flight at any given point in time
max_inflight: 4

# Note: IP addresses should be agents'
flow_graph:
  s-0:
    - name: w4
      peers: [2-0]
      addr: 10.20.1.72
      backend: nccl
    - name: w9
      peers: [5-0]
      addr: 10.20.1.72
      backend: nccl
  0-0:
    - name: w0
      peers: [s-0]
      addr: 10.20.1.72
      backend: nccl
  1-0:
    - name: w1
      peers: [0-0]
      addr: 10.20.1.72
      backend: nccl
    - name: w10
      peers: [3-0]
      addr: 10.20.1.72
      backend: nccl
  2-0:
    - name: w2
      peers: [1-0]
      addr: 10.20.1.72
      backend: nccl
    - name: w11
      peers: [4-0]
      addr: 10.20.1.72
      backend: nccl
  3-0:
    - name: w5
      peers: [s-0]
      addr: 10.20.1.50
      backend: nccl
  4-0:
    - name: w6
      peers: [3-0]
      addr: 10.20.1.50
      backend: nccl
    - name: w12
      peers: [0-0]
      addr: 10.20.1.50
      backend: nccl
  5-0:
    - name: w7
      peers: [4-0]
      addr: 10.20.1.50
      backend: nccl
    - name: w13
      peers: [1-0]
      addr: 10.20.1.50
      backend: nccl
dataset: # huggingface dataset
  path: fka/awesome-chatgpt-prompts
  name: ""
  split: train

workers:
  - id: s-0
    device: cuda:0
    is_server: true
    stage:
      start: -1
      end: -1
  - id: 0-0
    device: cuda:1
    stage:
      start: 0
      end: 10
  - id: 1-0
    device: cuda:2
    stage:
      start: 11
      end: 23
  - id: 2-0
    device: cuda:3
    stage:
      start: 24
      end: 34
  - id: 3-0
    device: cuda:1
    stage:
      start: 0
      end: 10
  - id: 4-0
    device: cuda:2
    stage:
      start: 11
      end: 23
  - id: 5-0
    device: cuda:3
    stage:
      start: 24
      end: 34
